#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
æ—¶é—´çª—å£ç¥ç»å…ƒçŠ¶æ€åˆ†æ - å¢å¼ºç‰ˆä½¿ç”¨ç¤ºä¾‹

è¯¥ç¤ºä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨å®Œå–„åçš„State_analysis.pyè¿›è¡Œï¼š
1. GCNåŠŸèƒ½éªŒè¯
2. ä¼ ç»Ÿæ—¶é—´çª—å£åˆ†æ
3. GCNæ—¶é—´çª—å£åˆ†æ
4. å…ˆè¿›GCNåˆ†æï¼ˆåŒ…å«æ³¨æ„åŠ›æœºåˆ¶å’Œæ—¶åºç‰¹å¾ï¼‰
5. ç»“æœå¯¹æ¯”å’Œåˆ†æ
"""

import os
import sys
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# æ·»åŠ è·¯å¾„ä»¥å¯¼å…¥State_analysisæ¨¡å—
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from State_analysis import EnhancedStateAnalyzer, verify_gcn_functionality

def main():
    """ä¸»å‡½æ•°ï¼šæ¼”ç¤ºå®Œæ•´çš„GCNå¢å¼ºåˆ†ææµç¨‹"""
    
    print("ğŸ§  ç¥ç»å…ƒçŠ¶æ€åˆ†æ - GCNå¢å¼ºç‰ˆæ¼”ç¤º")
    print("=" * 60)
    
    # 1. åˆå§‹åŒ–åˆ†æå™¨
    analyzer = EnhancedStateAnalyzer(
        sampling_rate=4.8,
        window_duration=30.0,
        overlap_ratio=0.5
    )
    
    # 2. é¦–å…ˆéªŒè¯GCNåŠŸèƒ½
    print("\nğŸ“‹ æ­¥éª¤1: éªŒè¯GCNåŠŸèƒ½")
    verify_gcn_functionality(analyzer)
    
    # 3. åŠ è½½ç¤ºä¾‹æ•°æ®
    print("\nğŸ“‹ æ­¥éª¤2: åŠ è½½æ•°æ®")
    data_path = '../datasets/processed_EMtrace01.xlsx'
    
    if not os.path.exists(data_path):
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
        print("ğŸ’¡ è¯·ç¡®ä¿æ•°æ®æ–‡ä»¶å­˜åœ¨ï¼Œæˆ–ä¿®æ”¹data_pathå˜é‡")
        return
    
    try:
        data = analyzer.load_data(data_path)
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {data.shape}")
        print(f"ğŸ“Š ç¥ç»å…ƒæ•°é‡: {len([col for col in data.columns if col.startswith('n')])}")
        print(f"â±ï¸  æ—¶é—´ç‚¹æ•°: {len(data)}")
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return
    
    # 4. åˆ›å»ºè¾“å‡ºç›®å½•
    output_base = '../results/gcn_enhanced_analysis'
    os.makedirs(output_base, exist_ok=True)
    
    # 5. è¿è¡Œä¸åŒçš„åˆ†ææ–¹æ³•å¹¶æ¯”è¾ƒç»“æœ
    methods_to_test = [
        ('ensemble', 'ä¼ ç»Ÿé›†æˆæ–¹æ³•'),
        ('gcn_temporal', 'GCNæ—¶é—´çª—å£åˆ†æ'),
        ('advanced_gcn', 'å…ˆè¿›GCNåˆ†æï¼ˆåŸºç¡€ï¼‰'),
        ('advanced_gcn_enhanced', 'å…ˆè¿›GCNåˆ†æï¼ˆå®Œæ•´åŠŸèƒ½ï¼‰')
    ]
    
    analysis_results = {}
    
    for method_key, method_name in methods_to_test:
        print(f"\nğŸ“‹ æ­¥éª¤3.{len(analysis_results)+1}: {method_name}")
        print("-" * 40)
        
        method_output_dir = os.path.join(output_base, method_key)
        os.makedirs(method_output_dir, exist_ok=True)
        
        try:
            if method_key == 'ensemble':
                # ä¼ ç»Ÿé›†æˆæ–¹æ³•
                labels, results_df = analyzer.analyze_temporal_states(
                    data, method='ensemble', n_states=4
                )
                
            elif method_key == 'gcn_temporal':
                # GCNæ—¶é—´çª—å£åˆ†æ
                labels, results_df = analyzer.gcn_temporal_analysis(
                    data, method='gcn', n_states=4
                )
                
            elif method_key == 'advanced_gcn':
                # å…ˆè¿›GCNåˆ†æï¼ˆåŸºç¡€é…ç½®ï¼‰
                labels, results_df = analyzer.advanced_gcn_analysis(
                    data, 
                    method='advanced_gcn',
                    n_states=4,
                    use_attention=False,
                    use_temporal_features=False
                )
                
            elif method_key == 'advanced_gcn_enhanced':
                # å…ˆè¿›GCNåˆ†æï¼ˆå®Œæ•´åŠŸèƒ½ï¼‰
                labels, results_df = analyzer.advanced_gcn_analysis(
                    data,
                    method='advanced_gcn', 
                    n_states=4,
                    use_attention=True,
                    use_temporal_features=True
                )
            
            # ä¿å­˜ç»“æœ
            analysis_results[method_key] = {
                'labels': labels,
                'results_df': results_df,
                'method_name': method_name
            }
            
            # ç”Ÿæˆå¯è§†åŒ–
            analyzer.visualize_temporal_states(data, results_df, method_output_dir)
            
            # è¾“å‡ºå…³é”®ç»Ÿè®¡ä¿¡æ¯
            print(f"   âœ… åˆ†æå®Œæˆ")
            print(f"   ğŸ“Š æ—¶é—´çª—å£æ•°: {len(results_df)}")
            print(f"   ğŸ§  ç¥ç»å…ƒæ•°: {results_df['neuron_id'].nunique()}")
            print(f"   ğŸ¯ è¯†åˆ«çŠ¶æ€æ•°: {results_df['state_label'].nunique()}")
            
            # å¦‚æœæ˜¯GCNæ–¹æ³•ï¼Œæ˜¾ç¤ºé¢å¤–ä¿¡æ¯
            if 'graph_nodes' in results_df.columns:
                print(f"   ğŸ”— å¹³å‡å›¾èŠ‚ç‚¹æ•°: {results_df['graph_nodes'].mean():.1f}")
            if 'graph_edges' in results_df.columns:
                print(f"   ğŸŒ å¹³å‡å›¾è¾¹æ•°: {results_df['graph_edges'].mean():.1f}")
            if 'feature_dim' in results_df.columns:
                print(f"   ğŸ“ ç‰¹å¾ç»´åº¦: {results_df['feature_dim'].iloc[0] if len(results_df) > 0 else 'N/A'}")
            
        except Exception as e:
            print(f"   âŒ {method_name} åˆ†æå¤±è´¥: {e}")
            analyzer.logger.error(f"{method_name} åˆ†æå¤±è´¥: {e}")
    
    # 6. ç»“æœå¯¹æ¯”åˆ†æ
    if len(analysis_results) > 1:
        print(f"\nğŸ“‹ æ­¥éª¤4: ç»“æœå¯¹æ¯”åˆ†æ")
        print("-" * 40)
        
        comparison_results = compare_analysis_results(analysis_results)
        plot_comparison_results(comparison_results, output_base)
        
        # ä¿å­˜å¯¹æ¯”ç»“æœ
        comparison_df = pd.DataFrame(comparison_results).T
        comparison_file = os.path.join(output_base, 'method_comparison.xlsx')
        comparison_df.to_excel(comparison_file)
        print(f"ğŸ“Š å¯¹æ¯”ç»“æœä¿å­˜è‡³: {comparison_file}")
    
    # 7. ç”Ÿæˆä½¿ç”¨æŠ¥å‘Š
    print(f"\nğŸ“‹ æ­¥éª¤5: ç”Ÿæˆä½¿ç”¨æŠ¥å‘Š")
    generate_usage_report(analysis_results, output_base)
    
    print(f"\nğŸ‰ æ‰€æœ‰åˆ†æå®Œæˆï¼")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {output_base}")
    print(f"ğŸ“š æŸ¥çœ‹å„æ–¹æ³•çš„è¯¦ç»†ç»“æœå’Œå¯è§†åŒ–")


def compare_analysis_results(analysis_results):
    """
    å¯¹æ¯”ä¸åŒåˆ†ææ–¹æ³•çš„ç»“æœ
    
    Parameters
    ----------
    analysis_results : dict
        å„æ–¹æ³•çš„åˆ†æç»“æœ
        
    Returns
    -------
    dict
        å¯¹æ¯”ç»“æœå­—å…¸
    """
    comparison = {}
    
    for method_key, result in analysis_results.items():
        results_df = result['results_df']
        method_name = result['method_name']
        
        # åŸºæœ¬ç»Ÿè®¡
        comparison[method_key] = {
            'method_name': method_name,
            'total_windows': len(results_df),
            'num_neurons': results_df['neuron_id'].nunique(),
            'num_states': results_df['state_label'].nunique(),
            'avg_window_duration': results_df['duration'].mean(),
        }
        
        # çŠ¶æ€åˆ†å¸ƒå‡åŒ€æ€§ (ç†µ)
        state_counts = results_df['state_label'].value_counts()
        state_probs = state_counts / state_counts.sum()
        entropy = -np.sum(state_probs * np.log2(state_probs + 1e-10))
        comparison[method_key]['state_entropy'] = entropy
        
        # ç¥ç»å…ƒçŠ¶æ€å¤šæ ·æ€§
        neuron_diversity = results_df.groupby('neuron_id')['state_label'].nunique()
        comparison[method_key]['avg_neuron_diversity'] = neuron_diversity.mean()
        comparison[method_key]['max_neuron_diversity'] = neuron_diversity.max()
        
        # GCNç‰¹å®šæŒ‡æ ‡
        if 'graph_nodes' in results_df.columns:
            comparison[method_key]['avg_graph_nodes'] = results_df['graph_nodes'].mean()
            comparison[method_key]['avg_graph_edges'] = results_df['graph_edges'].mean()
            comparison[method_key]['graph_density'] = (results_df['graph_edges'].mean() / 
                                                     (results_df['graph_nodes'].mean() * 
                                                      (results_df['graph_nodes'].mean() - 1)))
        else:
            comparison[method_key]['avg_graph_nodes'] = 'N/A'
            comparison[method_key]['avg_graph_edges'] = 'N/A'
            comparison[method_key]['graph_density'] = 'N/A'
    
    return comparison


def plot_comparison_results(comparison_results, output_dir):
    """
    ç»˜åˆ¶æ–¹æ³•å¯¹æ¯”ç»“æœå›¾è¡¨
    
    Parameters
    ----------
    comparison_results : dict
        å¯¹æ¯”ç»“æœ
    output_dir : str
        è¾“å‡ºç›®å½•
    """
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    
    methods = list(comparison_results.keys())
    method_names = [comparison_results[m]['method_name'] for m in methods]
    
    # 1. è¯†åˆ«çŠ¶æ€æ•°å¯¹æ¯”
    state_nums = [comparison_results[m]['num_states'] for m in methods]
    axes[0, 0].bar(method_names, state_nums)
    axes[0, 0].set_title('Identified States by Method')
    axes[0, 0].set_ylabel('Number of States')
    axes[0, 0].tick_params(axis='x', rotation=45)
    
    # 2. çŠ¶æ€åˆ†å¸ƒç†µå¯¹æ¯”
    entropies = [comparison_results[m]['state_entropy'] for m in methods]
    axes[0, 1].bar(method_names, entropies)
    axes[0, 1].set_title('State Distribution Entropy')
    axes[0, 1].set_ylabel('Entropy (bits)')
    axes[0, 1].tick_params(axis='x', rotation=45)
    
    # 3. ç¥ç»å…ƒçŠ¶æ€å¤šæ ·æ€§å¯¹æ¯”
    diversities = [comparison_results[m]['avg_neuron_diversity'] for m in methods]
    axes[0, 2].bar(method_names, diversities)
    axes[0, 2].set_title('Average Neuron State Diversity')
    axes[0, 2].set_ylabel('States per Neuron')
    axes[0, 2].tick_params(axis='x', rotation=45)
    
    # 4. å›¾èŠ‚ç‚¹æ•°å¯¹æ¯”ï¼ˆä»…GCNæ–¹æ³•ï¼‰
    gcn_methods = [m for m in methods if comparison_results[m]['avg_graph_nodes'] != 'N/A']
    if gcn_methods:
        gcn_names = [comparison_results[m]['method_name'] for m in gcn_methods]
        node_nums = [comparison_results[m]['avg_graph_nodes'] for m in gcn_methods]
        axes[1, 0].bar(gcn_names, node_nums)
        axes[1, 0].set_title('Average Graph Nodes (GCN Methods)')
        axes[1, 0].set_ylabel('Number of Nodes')
        axes[1, 0].tick_params(axis='x', rotation=45)
    else:
        axes[1, 0].text(0.5, 0.5, 'No GCN Methods', ha='center', va='center', transform=axes[1, 0].transAxes)
        axes[1, 0].set_title('Average Graph Nodes (GCN Methods)')
    
    # 5. å›¾è¾¹æ•°å¯¹æ¯”ï¼ˆä»…GCNæ–¹æ³•ï¼‰
    if gcn_methods:
        edge_nums = [comparison_results[m]['avg_graph_edges'] for m in gcn_methods]
        axes[1, 1].bar(gcn_names, edge_nums)
        axes[1, 1].set_title('Average Graph Edges (GCN Methods)')
        axes[1, 1].set_ylabel('Number of Edges')
        axes[1, 1].tick_params(axis='x', rotation=45)
    else:
        axes[1, 1].text(0.5, 0.5, 'No GCN Methods', ha='center', va='center', transform=axes[1, 1].transAxes)
        axes[1, 1].set_title('Average Graph Edges (GCN Methods)')
    
    # 6. è®¡ç®—æ•ˆç‡å¯¹æ¯”ï¼ˆæ¨¡æ‹Ÿï¼‰
    # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œåº”è¯¥è®°å½•å®é™…çš„è®¡ç®—æ—¶é—´
    efficiency_scores = []
    for method in methods:
        if 'advanced_gcn' in method:
            score = 0.6  # GCNæ–¹æ³•è®¡ç®—è¾ƒæ…¢ä½†ç»“æœå¯èƒ½æ›´å¥½
        elif 'gcn' in method:
            score = 0.7
        else:
            score = 0.9  # ä¼ ç»Ÿæ–¹æ³•è¾ƒå¿«
        efficiency_scores.append(score)
    
    axes[1, 2].bar(method_names, efficiency_scores)
    axes[1, 2].set_title('Computational Efficiency (Simulated)')
    axes[1, 2].set_ylabel('Efficiency Score')
    axes[1, 2].tick_params(axis='x', rotation=45)
    axes[1, 2].set_ylim(0, 1)
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'method_comparison.png'), dpi=300, bbox_inches='tight')
    plt.close()


def generate_usage_report(analysis_results, output_dir):
    """
    ç”Ÿæˆä½¿ç”¨æŠ¥å‘Š
    
    Parameters
    ----------
    analysis_results : dict
        åˆ†æç»“æœ
    output_dir : str
        è¾“å‡ºç›®å½•
    """
    report_file = os.path.join(output_dir, 'usage_report.md')
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("# ç¥ç»å…ƒçŠ¶æ€åˆ†æ - GCNå¢å¼ºç‰ˆä½¿ç”¨æŠ¥å‘Š\n\n")
        f.write("## åˆ†ææ¦‚è¿°\n\n")
        f.write("æœ¬æ¬¡åˆ†æä½¿ç”¨äº†å¤šç§æ–¹æ³•æ¥è¯†åˆ«ç¥ç»å…ƒçš„æ”¾ç”µçŠ¶æ€ï¼ŒåŒ…æ‹¬ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ–¹æ³•å’Œæœ€æ–°çš„å›¾ç¥ç»ç½‘ç»œæ–¹æ³•ã€‚\n\n")
        
        f.write("## æ–¹æ³•å¯¹æ¯”\n\n")
        f.write("| æ–¹æ³• | æ—¶é—´çª—å£æ•° | ç¥ç»å…ƒæ•° | è¯†åˆ«çŠ¶æ€æ•° | å¹³å‡ç¥ç»å…ƒå¤šæ ·æ€§ |\n")
        f.write("|------|------------|----------|------------|------------------|\n")
        
        for method_key, result in analysis_results.items():
            method_name = result['method_name']
            results_df = result['results_df']
            
            neuron_diversity = results_df.groupby('neuron_id')['state_label'].nunique().mean()
            
            f.write(f"| {method_name} | {len(results_df)} | {results_df['neuron_id'].nunique()} | "
                   f"{results_df['state_label'].nunique()} | {neuron_diversity:.2f} |\n")
        
        f.write("\n## GCNæ–¹æ³•ç‰¹ç‚¹\n\n")
        f.write("### ä¼˜åŠ¿\n")
        f.write("- ğŸ§  **å›¾ç»“æ„å»ºæ¨¡**: é€šè¿‡ç›¸ç©ºé—´é‡æ„å°†æ—¶é—´åºåˆ—è½¬æ¢ä¸ºå›¾ç»“æ„ï¼Œèƒ½å¤Ÿæ•è·å¤æ‚çš„éçº¿æ€§åŠ¨æ€\n")
        f.write("- ğŸ”— **å…³ç³»å­¦ä¹ **: GCNèƒ½å¤Ÿå­¦ä¹ èŠ‚ç‚¹ä¹‹é—´çš„å¤æ‚å…³ç³»å’Œæ¨¡å¼\n")
        f.write("- âš™ï¸ **æ³¨æ„åŠ›æœºåˆ¶**: å…ˆè¿›GCNåŒ…å«æ³¨æ„åŠ›æœºåˆ¶ï¼Œèƒ½å¤Ÿçªå‡ºé‡è¦ç‰¹å¾\n")
        f.write("- ğŸ“ˆ **æ—¶åºç‰¹å¾**: å¯ä»¥é›†æˆé€Ÿåº¦ã€åŠ é€Ÿåº¦ç­‰æ—¶åºç‰¹å¾ï¼Œæä¾›æ›´ä¸°å¯Œçš„ä¿¡æ¯\n\n")
        
        f.write("### ä½¿ç”¨å»ºè®®\n")
        f.write("- ğŸ“Š å¯¹äºå¤æ‚çš„éçº¿æ€§ç¥ç»å…ƒåŠ¨æ€ï¼Œæ¨èä½¿ç”¨ `advanced_gcn` æ–¹æ³•\n")
        f.write("- â±ï¸ å¯¹äºå¿«é€Ÿåˆ†æï¼Œå¯ä»¥ä½¿ç”¨ä¼ ç»Ÿçš„ `ensemble` æ–¹æ³•\n")
        f.write("- ğŸ”„ å¯¹äºä¸­ç­‰å¤æ‚åº¦çš„åˆ†æï¼Œ`gcn_temporal` æä¾›äº†å¹³è¡¡çš„é€‰æ‹©\n\n")
        
        f.write("## å‘½ä»¤è¡Œä½¿ç”¨ç¤ºä¾‹\n\n")
        f.write("```bash\n")
        f.write("# éªŒè¯GCNåŠŸèƒ½\n")
        f.write("python State_analysis.py --verify-gcn\n\n")
        f.write("# ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•\n")
        f.write("python State_analysis.py --method ensemble --window-duration 30\n\n")
        f.write("# ä½¿ç”¨GCNæ—¶é—´çª—å£åˆ†æ\n")
        f.write("python State_analysis.py --method gcn_temporal --window-duration 60\n\n")
        f.write("# ä½¿ç”¨å®Œæ•´åŠŸèƒ½çš„å…ˆè¿›GCN\n")
        f.write("python State_analysis.py --method advanced_gcn --use-attention --use-temporal-features\n")
        f.write("```\n\n")
        
        f.write("## ç»“æœè§£é‡Š\n\n")
        f.write("- **State Label**: è¯†åˆ«çš„çŠ¶æ€ç¼–å·ï¼ˆ0, 1, 2, ...ï¼‰\n")
        f.write("- **Graph Nodes**: ç›¸ç©ºé—´é‡æ„åçš„å›¾èŠ‚ç‚¹æ•°é‡\n")
        f.write("- **Graph Edges**: å›¾ä¸­çš„è¾¹æ•°é‡ï¼Œåæ˜ äº†è½¨è¿¹çš„è¿æ¥å¤æ‚åº¦\n")
        f.write("- **Feature Dim**: å¢å¼ºç‰¹å¾çš„ç»´åº¦ï¼ˆåŒ…å«ä½ç½®ã€é€Ÿåº¦ã€åŠ é€Ÿåº¦ç­‰ï¼‰\n\n")
        
        f.write("## æ³¨æ„äº‹é¡¹\n\n")
        f.write("- ğŸ”§ ç¡®ä¿å®‰è£…äº†PyTorchå’ŒPyTorch Geometric: `pip install torch torch-geometric`\n")
        f.write("- ğŸ’¾ GCNæ–¹æ³•éœ€è¦æ›´å¤šå†…å­˜å’Œè®¡ç®—èµ„æº\n")
        f.write("- â³ è®­ç»ƒæ—¶é—´ä¼šæ¯”ä¼ ç»Ÿæ–¹æ³•é•¿ï¼Œä½†ç»“æœé€šå¸¸æ›´å‡†ç¡®\n")
        f.write("- ğŸ“ å»ºè®®æ ¹æ®æ•°æ®å¤æ‚åº¦è°ƒæ•´çª—å£å¤§å°å’Œé‡å æ¯”ä¾‹\n")
    
    print(f"ğŸ“„ ä½¿ç”¨æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")


if __name__ == "__main__":
    main() 